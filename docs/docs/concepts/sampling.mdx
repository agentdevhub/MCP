---
标题: "采样功能"  
描述: "让您的服务器能够通过大模型获取补全结果"  
---

采样是MCP的一项强大功能，它允许服务器通过客户端请求大模型补全，在保障安全与隐私的同时实现复杂的智能体行为。

<Info>
  This feature of MCP is not yet supported in the Claude Desktop client.
</Info>

## 工作原理

采样流程遵循以下步骤：

1. 服务器向客户端发送`sampling/createMessage`请求  
2. 客户端审核并可能修改该请求  
3. 客户端从大模型获取采样结果  
4. 客户端审核补全内容  
5. 客户端将结果返回服务器  

这种"人在回路"设计确保用户始终控制大模型的输入与输出。

## 消息格式

采样请求采用标准化消息格式：

```typescript
{
  messages: [
    {
      role: "user" | "assistant",
      content: {
        type: "text" | "image",

        // For text:
        text?: string,

        // For images:
        data?: string,             // base64 encoded
        mimeType?: string
      }
    }
  ],
  modelPreferences?: {
    hints?: [{
      name?: string                // Suggested model name/family
    }],
    costPriority?: number,         // 0-1, importance of minimizing cost
    speedPriority?: number,        // 0-1, importance of low latency
    intelligencePriority?: number  // 0-1, importance of capabilities
  },
  systemPrompt?: string,
  includeContext?: "none" | "thisServer" | "allServers",
  temperature?: number,
  maxTokens: number,
  stopSequences?: string[],
  metadata?: Record<string, unknown>
}
```

## 请求参数

### 消息内容

`messages`数组包含发送给大模型的对话历史。每条消息包含：

- `role`：取值为"user"或"assistant"  
- `content`：消息内容，可以是：  
  - 文本内容（含`text`字段）  
  - 图像内容（含`data` base64编码字段和`mimeType`字段）  

### 模型偏好

`modelPreferences`对象允许服务器指定模型选择偏好：

- `hints`：模型名称建议数组，客户端可据此选择合适模型：  
  - `name`：可匹配完整或部分模型名称的字符串（如"claude-3"，"sonnet"）  
  - 客户端可将提示映射到不同提供商的等效模型  
  - 多个提示按优先顺序评估  

- 优先级参数（0-1标准化值）：  
  - `costPriority`：成本最小化的重要性  
  - `speedPriority`：低延迟响应的重要性  
  - `intelligencePriority`：高级模型能力的重要性  

客户端根据这些偏好和可用模型做出最终选择。

### 系统提示词

可选`systemPrompt`字段允许服务器请求特定系统提示词，客户端可修改或忽略该请求。

### 上下文包含

`includeContext`参数指定要包含的MCP上下文范围：

- `"none"`：不包含额外上下文  
- `"thisServer"`：包含请求服务器的上下文  
- `"allServers"`：包含所有连接MCP服务器的上下文  

实际包含内容由客户端控制。

### 采样参数

可通过以下参数微调大模型采样：

- `temperature`：控制随机性（0.0至1.0）  
- `maxTokens`：生成的最大token数  
- `stopSequences`：终止生成的序列数组  
- `metadata`：供应商特定附加参数  

## 响应格式

客户端返回补全结果：

```typescript
{
  model: string,  // Name of the model used
  stopReason?: "endTurn" | "stopSequence" | "maxTokens" | string,
  role: "user" | "assistant",
  content: {
    type: "text" | "image",
    text?: string,
    data?: string,
    mimeType?: string
  }
}
```

## 请求示例

以下是向客户端请求采样的示例：
```json
{
  "method": "sampling/createMessage",
  "params": {
    "messages": [
      {
        "role": "user",
        "content": {
          "type": "text",
          "text": "What files are in the current directory?"
        }
      }
    ],
    "systemPrompt": "You are a helpful file system assistant.",
    "includeContext": "thisServer",
    "maxTokens": 100
  }
}
```

## 最佳实践

实施采样时建议：

1. 始终提供清晰、结构化的提示词  
2. 正确处理文本和图像内容  
3. 设置合理的token限制  
4. 通过`includeContext`包含相关上下文  
5. 使用前验证响应内容  
6. 优雅处理错误  
7. 考虑实施速率限制  
8. 记录预期的采样行为  
9. 测试不同模型参数  
10. 监控采样成本  

## 人工控制机制

采样功能设计强调人工监督：

### 提示词控制

- 客户端应向用户展示拟发送的提示词  
- 用户应能修改或拒绝提示词  
- 系统提示词可被过滤或修改  
- 上下文包含由客户端控制  

### 补全控制

- 客户端应向用户展示补全结果  
- 用户应能修改或拒绝补全内容  
- 客户端可过滤或修改补全结果  
- 用户控制所用模型选择  

## 安全考量

实施采样时需注意：

- 验证所有消息内容  
- 脱敏敏感信息  
- 实施适当的速率限制  
- 监控采样使用情况  
- 传输数据加密  
- 处理用户数据隐私  
- 审计采样请求  
- 控制成本风险  
- 设置超时机制  
- 优雅处理模型错误  

## 常见模式

### 智能体工作流

采样支持以下智能体模式：

- 读取分析资源  
- 基于上下文决策  
- 生成结构化数据  
- 处理多步骤任务  
- 提供交互式协助  

### 上下文管理

上下文最佳实践：

- 仅请求必要最小上下文  
- 清晰组织上下文结构  
- 处理上下文大小限制  
- 按需更新上下文  
- 清理过期上下文  

### 错误处理

健壮的错误处理应：

- 捕获采样失败  
- 处理超时错误  
- 管理速率限制  
- 验证响应内容  
- 提供回退机制  
- 规范错误日志  

## 限制条件

需注意以下限制：

- 采样依赖客户端能力  
- 用户控制采样行为  
- 上下文存在大小限制  
- 可能适用速率限制  
- 需考虑成本因素  
- 模型可用性各异  
- 响应时间波动  
- 非所有内容类型都被支持